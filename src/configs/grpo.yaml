# The hyperparameters for the GRPO training are defined to be the same as the ones in the original paper:
# https://arxiv.org/pdf/2402.03300
bf16: true

# training
do_train: true
output_dir: "/scratch/prj/charnu/ft_weights/mental-healer/grpo_qwen8/"
per_device_train_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 1.0e-5
num_train_epochs: 1

# optimizer
adam_beta1: 0.9
adam_beta2: 0.95
weight_decay: 0.1

# vllm settings
use_vllm: true
vllm_mode: "server"

# logging
logging_steps: 10
logging_first_step: true
log_completions: true