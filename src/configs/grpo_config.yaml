# The hyperparameters for the GRPO training are defined to be the same as the ones in the original paper:
# https://arxiv.org/pdf/2402.03300
bf16: true
model_init_kwargs:
  torch_dtype: bfloat16

# sampling
num_generations: 8

# training
do_train: true
output_dir: "/scratch/prj/charnu/ft_weights/mental-healer/grpo_qwen8/"
per_device_train_batch_size: 2
gradient_accumulation_steps: 8
learning_rate: 1.0e-5
num_train_epochs: 1

# optimizer
adam_beta1: 0.9
adam_beta2: 0.95
weight_decay: 0.1

# vllm settings
use_vllm: true

# logging
logging_steps: 10
logging_first_step: true
log_completions: true